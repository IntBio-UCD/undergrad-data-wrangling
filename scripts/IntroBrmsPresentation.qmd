---
title: "A micro introduction to Bayesian modeling with BRMS"
author: "Julin Maloof"
format:
  revealjs:
    theme: sky
    margin: 0.075
    code-line-numbers: false
    embed-resources: true
    smaller: true
    scrollable: true
    incremental: true
---

```{r}
knitr::opts_chunk$set(cache = TRUE, autodep = TRUE)
```


```{r}
library(tidyverse)
library(brms)
```

## Frequentist vs Bayesian Statistics

:::: {.columns}

::: {.column width="50%" .nonincremental}
__Frequentist Statistics__

* What is the probability of the _data_ given a hypothesis
* Theory relies on data that is not observed
* Accept or reject null hypothesis
* Does not require use of priors
:::

::: {.column width="50%" .nonincremental}
__Bayesian__

* What is the probability of the _hypothesis_ given the data
* Does not rely on unobserved data
* Evaluate ratio of probabilities for different hypotheses
* Requires specification of prior beliefs (not as bad as it sounds!)
:::

::::

## Prior probabilities
* Bayesian methods require that we specify __prior probabilities__ on the model parameters
* This might sound like we are cheating
* Instead we use relatively __uninformative priors__
* As long as we have set relatively weak (uninformative) priors, the data will overwhelm the priors
* (Although if we do have prior information we can use informative priors)

## Sampling
* Bayesian model fitting requires sampling different parameter values
* For each set of parameters test, calculate the probability of the model, given the data
  - Similar to what we discussed two weeks ago with the `nls` function
* Difference is that for `nls` the goal was just to find the "BEST" set of parameters
* For Bayesian we need to sample enough to define the probability "landscape"
* Typically several thousand sets of parameter values are sampled

## Posterior probabilities

:::: {.columns}

::: {.column width="50%"}

* One output of Bayesian model fitting is a set of __posterior probabilities__ 
* These will give us the distribution of possible parameter values for each model parameter, given the data and the priors
* We can do further tests/comparisons once we have these posterior probabilities

:::

::: {.column width="50%" .nonincremental}

```{r}



tibble(slope=sample(seq(6,14, by = 0.01), size = 1000, replace = TRUE ),
       probability = dnorm(slope, mean=10)) %>%
       # probability=ifelse(slope < 10,
       #                    pnorm(q = slope, mean=10),
       #                    pnorm(q = slope, mean=10, lower.tail = FALSE))) %>%
  ggplot(aes(x=slope,y=probability)) +
  geom_point(alpha=.1) +
  ggtitle("Posterior Probability")
```
:::

::::


## Diagnostics
* It is critically important to evaluate whether the sampling worked well
* Typically four sampling "chains" are run
* `Rhat` compares variance between and within chains.  Should be < 1.05
* `ESS` (Effective sampling size) should be > 100 per chain

## Let's try it {.nonincremental}

```{r, echo=TRUE, eval=TRUE}
library(tidyverse)
library(brms)
dat <- read_csv("../output/height_data_clean.csv")
```

Please create two objects 

* `datsmall` that only retains observations from "2023-01-27"
* `datsmallbcd` that only retains  BH, CC, and DPR observations from "2023-01-27"
```{r}
datsmall <- dat %>% filter(survey_date=="2023-01-27") 

datsmallbcd <- datsmall %>% filter(str_detect(pop, "BH|CC|DPR"))
```

## Check the number of "cores" on our computer {.nonincremental}

* Most computers have multiple "cores" or CPUs that can be used in parallel.  
* Let's check what we have.  We will use this on the next slide.
```{r, echo=TRUE}
parallel::detectCores()
```

## What are the default priors?
* We will use what should now be a familiar formula to specify our model
* We can ask what priors would be used by default for our formula and data
```{r, echo=TRUE}
get_prior(height_cm ~ pop, 
          data = datsmallbcd)
```
* They "b" class are the coefficients on fixed effects.
* They have a flat prior (all values from -Infinity to +Infinity are equally likely)
* We can do better than this while still not biasing the model (next slide)
* Student_t is like a fat-tailed normal distribution.
  - The intercept is centered at 3.5, 
  - sigma (standard deviation) is centered at 0
  
## Student vs normal
```{r}
tibble(x=seq(-10,10,.1),
       normal=dnorm(x,sd=2.5),
       student_t=dstudent_t(x, 3, sigma = 2.5)) %>%
  pivot_longer(-x) %>%
  ggplot(aes(x=x,y=value, color=name)) +
  geom_line() +
  ggtitle("Normal vs Student_t, sd=2.5")
```


## Fit a model with height being predicted by pop {.nonincremental}
```{r, echo=TRUE, eval=FALSE}
m1 <- brm(height_cm ~ pop,
          data = datsmallbcd,
          prior = set_prior("normal(0,10)", class = "b"),
          sample_prior = TRUE,
          cores = 4) # set to 1 if you only have 1 core, or 2 if you have 2.
                       # don't go higher than 4, even if you have more than 4 cores.    
```

* We use an uninformative prior for "b", the coefficient for differences between pops
  - We are setting this prior to be normally distributed, centered on 0, with a standard deviation of 10
  - Note "b" refers to any fixed-effect coefficients.  If we had multiple fixed effects we could give them all the same prior, or we could specify them individually.
* By default brms uses 4 chains `cores = 4` means that we want each chain to run in parallel in a different CPU in our computer.
* By default, each chain has 1,000 warm-up samples and 1,000 real samples

## Fit a model with height being predicted by pop
__CORRECTED: `cores=4` not `threads=4`__
```{r, echo=TRUE, eval=TRUE}
m1 <- brm(height_cm ~ pop,
          data = datsmallbcd,
          prior = set_prior("normal(0,10)", class = "b"),
          sample_prior = TRUE,
          cores = 4)
```

The output shows us the progress of each chain

## Model summary

```{r, echo=TRUE}
summary(m1)
```
* `Estimate` is the estimated height
  - `Intercept` is for the reference population (BH in this case)
  - `popCC` is the estimated difference between CC and BH
* 95% confidence intervals show our confidence in the estimate.  
  If they do not cross 0, then we are at least 95% confident that our differences are real
* Be sure to check `Rhat` and the two `ESS` stats.  What did we want these to be?

## Model plots

```{r, echo=TRUE}
plot(m1, N=3, ask=FALSE)
```
* On the left we see the distribution of the posterior probability 
  - Check for unusual pattern, bimodality, etc.
  - If the posterior is near the edge of the range of the prior, consider adjusting the prior
* On the right we see the value for each parameter for each sample of each chain
  - Should look relatively uniform from left to right and chains should look similar
  
## what are the other priors?

Our posterior plots had two coefficients that we did not specify priors for.  What was used?

```{r}
prior_summary(m1)
```


## Bayesian hypothesis testing {.nonincremental}

* Is popCC really different from popBH?
* Looking for 
  - `Post_prob` to be near 1 (probability that hypothesis is true)
  - `Evid.Ratio`  > 3 (>3 = "moderate evidence", > 10 = "strong evidence")
```{r, echo=TRUE}
hypothesis(m1, hypothesis = "popCC > 0")
```


## Getting posterior probability for an estimate {.nonincremental}
Sometime I prefer to do this by "hand"
```{r, echo=TRUE}
posterior <- m1 %>% as_draws_df()
dim(posterior)
head(posterior)
```

## How many draws are less than 0?
```{r, echo=TRUE}
posterior %>% 
  summarize(CC_greater_than_zero = sum(b_popCC > 0)/n())
```
* All 4000 posterior samples estimate the the CC coefficient is > 0
* This is very strong evidence the CC height is greater than BH height

## Bayesian hypothesis testing {.nonincremental}

* Is popCC the same height as popDPR?
* Looking for 
  - `Post_prob` to be near 1 (probability that hypothesis is true)
  - `Evid.Ratio` to > 3 (>3 = "moderate evidence", > 10 = "strong evidence")
```{r, echo=TRUE}
hypothesis(m1, hypothesis = "popCC = popDPR")
```

## Fit a model with random effects: {.nonincremental}

* Really pop and block should probably both be random, but we will keep pop fixed for now
```{r, echo=TRUE}
m2 <- brm(height_cm ~ pop + (1|block),
          data = datsmallbcd,
          prior = set_prior("normal(0,10)", class = "b"),
          sample_prior = TRUE,
          threads = 4)
```

## what priors were used for random effects?
```{r, echo=TRUE}
prior_summary(m2)
```

## Check model sampling (do your own)

## summary
```{r}
summary(m2)
```

## plots
```{r}
plot(m2, N=3, ask=FALSE)
```


## Is it better than the model without the random effect?

```{r, echo=TRUE}
m1 <- add_criterion(m1, "loo")
m2 <- add_criterion(m2, "loo")
loo_compare(m1, m2)
```

* Preferred model is listed first
* `elpd_diff` is how much worse a model is relative to the preferred model
* Want this to be greater (ideally 2X greater) than `se_diff` to favor the more complex model

# Weibull in brms

## Data set:
Use all dates for the Weibull modeling
```{r, echo=TRUE}
dat <- read_csv("../output/height_data_clean.csv")

dat <- dat %>%
  mutate(day=as.numeric(survey_date-min(survey_date)+30),
         mf=factor(mf))

datbcd <- dat %>% filter(str_detect(pop, "BH|CC|DPR"))

```


## Non-linear model specification in brms

Our formula specification is a bit more complex, so we use the function `brmsformula` to define the non-linear formula.

I am also going to rename a couple of the parameters to be more clear
```{r, echo=TRUE}
f1 <- brmsformula(height_cm ~ Hmax - (Hmax - Hmin) * exp(-(k/100 * day)^delta),
                  Hmax + Hmin + k + delta ~ 1,
                  nl=TRUE)
```

* The first line should look familiar (Weibull formula)
  - I am dividing k by 100 just to get it on a more reasonable scale
* The second line is new, and it defines how each parameter should be fit with respect to the predictors in our data set.
* The notation `Hmax + Hmin + k + delta ~ 1` means that we want a single parameter value (Intercept) for each of the four parameters
* `nl=TRUE` tells brms that this is a non-linear formula.

## get the priors

Please review your notes and figure out how to get the possible priors for the formula on the previous slide

```{r}
get_prior(f1, data=datbcd)
```
## Set the priors

What priors should we use?

```{r echo=TRUE, eval=TRUE}
prior1 <- c(set_prior("normal(5,3)", nlpar="Hmin"),
            set_prior("normal(60,15)",  nlpar="Hmax"),
            set_prior("gamma(2,2)", nlpar = "k"), # gamma constrains to be > 0
            set_prior("gamma(20, 3)", nlpar="delta")
)
```

## Why gamma? {.nonincremental}

* Want to constrain k and delta to be > 0.
* Setting lower bounds causes problems
* Gamma distribution is positive

```{r, echo=TRUE}
tibble(x=seq(0,10,.1),
       gamma_2_2=dgamma(x, 2, 2),
       gamma_20_3=dgamma(x, 20, 3)) %>%
  pivot_longer(-x, values_to = "density") %>%
  ggplot(aes(x=x,y=density, color=name)) +
  geom_line()

```
## Fit the model

```{r, echo=TRUE}
fit1 <- brm(formula=f1, data=datbcd, prior=prior1, cores = 4)
```
## Get the summary
```{r, echo=TRUE}
summary(fit1)
```
## fit1 plots
```{r, echo=TRUE}
plot(fit1, N = 3, ask=FALSE)
```
## fit 1 predictions
```{r, echo=TRUE}
fit1.prediction <- cbind(datbcd, pred1=predict(fit1)[,"Estimate"])

fit1.prediction %>% ggplot(aes(x=day)) +
  geom_line(aes(group=plantID, y=height_cm), alpha=.1) +
  geom_line(aes(y=pred1), color="blue") 
```

## fit 1 plot predictions per pop
* Please write code to generate the plot below (you can do this by adding one function call to the code on the previous slide)
* In your own words, how did it do?
```{r}
fit1.prediction %>% ggplot(aes(x=day)) +
  geom_line(aes(group=plantID, y=height_cm), alpha=.1) +
  geom_line(aes(y=pred1), color="blue") +
  facet_wrap(~pop)
```

## Allow a different Hmax for each pop {.nonincremental)}

* The plants from different pops grow to different heights.  Maybe we should model that.  
* With only 3 pops we will use a fixed effect. (Need 5+ for random effect)
* See below for how we specify that Hmax should take on a different value for each pop
```{r, echo=TRUE}
f2 <- brmsformula(height_cm ~ Hmax - (Hmax - Hmin) * exp(-(k/100 * day)^delta),
                  Hmin + k + delta ~ 1,
                  Hmax ~ pop,
                  nl=TRUE)
```

## get the priors

Please review your notes and figure out how to get the possible priors for the formula on the previous slide

```{r}
get_prior(f2, data=datbcd)
```
## Set the priors
* Do these seem reasonable to you?
```{r echo=TRUE, eval=TRUE}
prior2 <- c(set_prior("normal(5,3)", nlpar="Hmin"),
            set_prior("normal(60,15)", nlpar="Hmax"),
            set_prior("normal(0,20)", nlpar="Hmax", coef="popCC"),
            set_prior("normal(0,20)", nlpar="Hmax", coef="popDPR"),
            set_prior("gamma(2,2)", nlpar = "k"), # gamma constrains to be > 0
            set_prior("gamma(20, 3)", nlpar="delta")
)
```

## Fit model 2
```{r, echo=TRUE}
fit2 <- brm(formula=f2, data=datbcd, prior=prior2, cores = 4)
```

## Fit 2 summary
Any Problems?
```{r, echo=TRUE}
summary(fit2)
```

## Fit 2 plots
Any problems?
```{r, echo=TRUE}
plot(fit2, N = 3, ask=FALSE)
```

## Fit 2 plot the predictions
```{r, echo=TRUE}
datbcd$pred2 <- predict(fit2)[,"Estimate"]

datbcd %>% ggplot(aes(x=day)) +
  geom_line(aes(group=plantID, y=height_cm, color=pop), alpha=.3) +
  geom_line(aes(y=pred2, color=pop)) +
  scale_color_brewer(type="qual", palette = "Set2", guide="none") +
  facet_wrap(~pop)
```

## Fit 2 Extend the CC and DPR curves out for all days {.nonincremental}
* It would be nice to get predictions for CC and DPR all the way out to day 200
* To do this, we create a data frame containing each day and pop for which we would like a prediction
* The function `expand_grid` creates a data frame with all combinations of the items it is given (days and pops in this case). 
```{r, echo=TRUE}
pred.df <- expand_grid(day=min(datbcd$day):max(datbcd$day),
                       pop=unique(datbcd$pop))
pred.df
```

## Fit 2 Extend the CC and DPR curves out for all days (slide 2)
* Now we use our prediction data frame to generate predictions
```{r, echo=TRUE}
fit2.predictions <- cbind(pred.df, prediction=predict(fit2, newdata = pred.df)[,"Estimate"]) %>%
  full_join(datbcd, by=c("day", "pop"))

fit2.predictions
```

## plot full predictions {.nonincremental}
* What do you think if the predictions?  Any better than model 1?  
* Do you agree with the Hmax values generated by the model?
* If not, why do you think the model is generating those values? (also see next slide)
```{r, echo=TRUE}
fit2.predictions %>% ggplot(aes(x=day)) +
  geom_line(aes(group=plantID, y=height_cm, color=pop), alpha=.2) +
  geom_line(aes(y=prediction, color=pop)) +
  scale_color_brewer(type="qual", palette = "Set2", guide="none") +
  facet_wrap(~pop)
```

## DPR data + all predictions {.nonincremental}
* This may be helpful in answering the last question
```{r, echo=TRUE}
fit2.predictions %>% ggplot(aes(x=day)) +
  geom_line(aes(group=plantID, y=height_cm, color=pop),
            alpha=.2,
            data = {fit2.predictions %>% filter(pop=="DPR")}) +
  geom_line(aes(y=prediction, color=pop)) +
  scale_color_brewer(type="qual", palette = "Set2") 
```

## Let's try a new model

* Having Hmax alone vary by population did not produce a very good fit.  
* Exercise: Create and fit a model that allows Hmax and k  parameters to vary by population
* Plot your results: Any better?
* Perform a model comparison among all 3 models using the `loo` technique shown about: which fits best?

## My formula

```{r, echo=TRUE}
f3 <- brmsformula(height_cm ~ Hmax - (Hmax - Hmin) * exp(-(k/100 * day)^delta),
                  Hmin + delta ~ 1,
                  Hmax + k ~ pop,
                  nl=TRUE)
```

## get the priors

Please review your notes and figure out how to get the possible priors for the formula on the previous slide

```{r}
get_prior(f3, data=datbcd)
```
## Set the priors

What priors should we use?

```{r echo=TRUE, eval=TRUE}
prior3 <- c(set_prior("normal(5,3)", lb=0, nlpar="Hmin"),
            set_prior("normal(60,15)", nlpar="Hmax"),
            set_prior("normal(0,20)", nlpar="Hmax", coef="popCC"),
            set_prior("normal(0,20)", nlpar="Hmax", coef="popDPR"),
            set_prior("gamma(2,2)", nlpar = "k"), # gamma constrains to be > 0
            set_prior("normal(0, 1)", nlpar = "k", coef="popCC"),
            set_prior("normal(0, 1)", nlpar = "k", coef= "popDPR"),
            set_prior("gamma(20, 3)", nlpar="delta")

)
```

## model summary
```{r}
fit3 <- brm(formula=f3, data=datbcd, prior=prior3, cores = 4)
```


```{r}
summary(fit3)
```

## model plot
```{r}
plot(fit3, N=3, ask=FALSE)
```

## pairs

```{r}
pairs(fit3, variable="CC", regex = TRUE)
```

## Predictions

```{r}
fit3.predictions <- cbind(pred.df, prediction=predict(fit3, newdata = pred.df)[,"Estimate"]) %>%
  full_join(datbcd, by=c("day", "pop"))
```

```{r}
fit3.predictions %>% ggplot(aes(x=day)) +
  geom_line(aes(group=plantID, y=height_cm, color=pop), alpha=.2) +
  geom_line(aes(y=prediction, color=pop)) +
  scale_color_brewer(type="qual", palette = "Set2", guide="none") +
  facet_wrap(~pop)
```

## Model comparison

## Next

* delta + Hmax
* delta + k + Hmax (doesn't work well...)
* Uncertainty on the predictions
* On to random effects and all pops
* CENSORED DATA?


